# Google Vertex AI

:::caution
You are currently on a page documenting the use of Google Vertex models as [text completion models](/docs/concepts/#llms). Many popular models available on Google Vertex are [chat completion models](/docs/concepts/#chat-models).

You may be looking for [this page instead](/docs/integrations/chat/google_vertex_ai/).
:::

LangChain.js supports two different authentication methods based on whether
you're running in a Node.js environment or a web environment.

## Setup

### Node.js

To call Vertex AI models in Node, you'll need to install the `@langchain/google-vertexai` package:

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/google-vertexai
```

You should make sure the Vertex AI API is
enabled for the relevant project and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.
  **or**
- You set the `GOOGLE_API_KEY` environment variable to the API key for the project.

### Web

To call Vertex AI models in web environments (like Edge functions), you'll need to install
the `@langchain/google-vertexai-web` package:

```bash npm2yarn
npm install @langchain/google-vertexai-web
```

Then, you'll need to add your service account credentials directly as a `GOOGLE_VERTEX_AI_WEB_CREDENTIALS` environment variable:

```
GOOGLE_VERTEX_AI_WEB_CREDENTIALS={"type":"service_account","project_id":"YOUR_PROJECT-12345",...}
```

You can also pass your credentials directly in code like this:

```typescript
import { VertexAI } from "@langchain/google-vertexai";
// Or uncomment this line if you're using the web version:
// import { VertexAI } from "@langchain/google-vertexai-web";

const model = new VertexAI({
  authOptions: {
    credentials: {"type":"service_account","project_id":"YOUR_PROJECT-12345",...},
  },
});
```

## Usage

The entire family of `gemini` models are available by specifying the `modelName` parameter.

import CodeBlock from "@theme/CodeBlock";
import VertexAILLMExample from "@examples/llms/googlevertexai.ts";

<CodeBlock language="typescript">{VertexAILLMExample}</CodeBlock>

### Streaming

Streaming in multiple chunks is supported for faster responses:

import VertexAILLMStreaming from "@examples/llms/googlevertexai-streaming.ts";

<CodeBlock language="typescript">{VertexAILLMStreaming}</CodeBlock>
