---
sidebar_label: Bedrock
---

# BedrockChat

> [Amazon Bedrock](https://aws.amazon.com/bedrock/) is a fully managed service that makes Foundation Models (FMs)
> from leading AI startups and Amazon available via an API. You can choose from a wide range of FMs to find the model that is best suited for your use case.

## Setup

:::tip
The `ChatBedrockConverse` chat model is now available via `@langchain/aws`. Access tool calling with more models with this package. 
:::

You'll need to install the `@langchain/community` package:

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/community
```

Then, you'll need to install a few official AWS packages as peer dependencies:

```bash npm2yarn
npm install @aws-crypto/sha256-js @aws-sdk/credential-provider-node @smithy/protocol-http @smithy/signature-v4 @smithy/eventstream-codec @smithy/util-utf8 @aws-sdk/types
```

You can also use BedrockChat in web environments such as Edge functions or Cloudflare Workers by omitting the `@aws-sdk/credential-provider-node` dependency
and using the `web` entrypoint:

```bash npm2yarn
npm install @aws-crypto/sha256-js @smithy/protocol-http @smithy/signature-v4 @smithy/eventstream-codec @smithy/util-utf8 @aws-sdk/types
```

## Usage

import UnifiedModelParamsTooltip from "@mdx_components/unified_model_params_tooltip.mdx";

<UnifiedModelParamsTooltip></UnifiedModelParamsTooltip>

Currently, only Anthropic, Cohere, and Mistral models are supported with the chat model integration. For foundation models from AI21 or Amazon, see [the text generation Bedrock variant](/docs/integrations/llms/bedrock).

import CodeBlock from "@theme/CodeBlock";
import BedrockExample from "@examples/models/chat/integration_bedrock.ts";

<CodeBlock language="typescript">{BedrockExample}</CodeBlock>

## Multimodal inputs

:::tip
Multimodal inputs are currently only supported by Anthropic Claude-3 models.
:::

Anthropic Claude-3 models hosted on Bedrock have multimodal capabilities and can reason about images. Here's an example:

import BedrockMultimodalExample from "@examples/models/chat/integration_bedrock_multimodal.ts";

<CodeBlock language="typescript">{BedrockMultimodalExample}</CodeBlock>

### Tool calling

:::info
Not all Bedrock models support tool calling. Please refer to the [model documentation](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html) for more information.
:::

The examples below demonstrate how to use tool calling, along with the `withStructuredOutput` method to easily compose structured output LLM calls.

import ToolCalling from "@examples/models/chat/integration_bedrock_tools.ts";

<CodeBlock language="typescript">{ToolCalling}</CodeBlock>

:::tip
See the LangSmith trace [here](https://smith.langchain.com/public/003a684d-90eb-406e-a146-8ee5e617921b/r)
:::

#### `.withStructuredOutput({ ... })`

Using the `.withStructuredOutput` method, you can easily make the LLM return structured output, given only a Zod or JSON schema:

import WSOExample from "@examples/models/chat/integration_bedrock_wso.ts";

<CodeBlock language="typescript">{WSOExample}</CodeBlock>

:::tip
See the LangSmith trace [here](https://smith.langchain.com/public/1f7b1ad8-e4ac-4965-8ce1-fae06005f3d7/r)
:::
