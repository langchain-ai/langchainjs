# Azure Machine Learning Chat

You can deploy models on Azure with the endpointUrl, apiKey, and deploymentName
when creating the AzureMLChatParams to call upon later. You must import a ContentFormatter
or create your own using the ChatContentFormatter interface.

```typescript
import {
  AzureMLChatParams,
  LlamaContentFormatter,
} from "langchain/chat_models/azure_ml";

const model = new AzureMLOnlineEndpoint({
  endpointUrl: "YOUR_ENDPOINT_URL",
  endpointApiKey: "YOUR_ENDPOINT_API_KEY",
  deploymentName: "YOUR_MODEL_DEPLOYMENT_NAME",
  contentFormatter: new LlamaContentFormatter(),
});

const res = model.invoke(["Foo"]);
console.log({ res });
```
